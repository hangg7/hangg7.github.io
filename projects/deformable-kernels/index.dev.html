<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
  <head>
        <title>Deformable Kernels</title>
        <meta property="og:title" content="deformable-kernels" />
  </head>

  <body>
    <br>
    <center>
        <span style="font-size:32px">
            Deformable Kernels:
            <br>
            Adapting Effective Receptive Fields for Object Deformation
        </span>
    </center>
    <br>
    <table align=center width=800px>
        <tr>
            <td align=center width=100px>
                <center>
                    <span style="font-size:20px">
                        <a href="https://people.eecs.berkeley.edu/~hangg/">Hang Gao</a><sup>1,3,*</sup>
                    </span>
                </center>
            </td>
            <td align=center width=100px>
                <center>
                    <span style="font-size:20px">
                        <a href="https://scholar.google.com/citations?hl=en&user=02RXI00AAAAJ">Xizhou Zhu</a><sup>2,3,*</sup>
                    </span>
                </center>
            </td>
            <td align=center width=100px>
                <center>
                    <span style="font-size:20px">
                        <a href="https://scholar.google.com/citations?user=c3PYmxUAAAAJ&hl=en&oi=ao">Steve Lin</a><sup>3</sup>
                    </span>
                </center>
            </td>
            <td align=center width=100px>
                <center>
                    <span style="font-size:20px">
                        <a href="https://jifengdai.org/">Jifeng Dai</a><sup>3</sup>
                    </span>
                </center>
            </td>
        </tr>
    </table>
    <table align=center width=700px>
        <tr>
            <td align=center width=100px>
                <center>
                    <span style="font-size:20px">
                        <sup>1</sup>UC Berkeley
                    </span>
                </center>
            </td>
            <td align=center width=100px>
                <center>
                    <span style="font-size:20px">
                        <sup>2</sup>USTC
                    </span>
                </center>
            </td>
            <td align=center width=100px>
                <center>
                    <span style="font-size:20px">
                        <sup>3</sup>Microsoft Research Asia
                    </span>
                </center>
            </td>
        </tr>
    </table>
    <br>
    <table align=center width=500px>
        <tr>
            <td align=center width=100px>
                <center>
                    <span style="font-size:20px">
                        <a href="https://arxiv.org/abs/1910.02940">[ICLR 2020]</a>
                    </span>
                </center>
            </td>
            <td align=center width=100px>
                <center>
                    <span style="font-size:20px">
                        <a href="https://arxiv.org/abs/1910.02940">[Code]</a>
                    </span>
                </center>
            </td>
        </tr>
    </table>


    <br>
    <table align=center width=600px>
        <tr>
            <td width=700px>
                <center>
                    <img src="resources/teaser.png" height="448px"></img><br>
                </center>
            </td>
        </tr>
        <tr>
            <td width=600px>
                <center>
                    <span style="font-size:14px">
                        <i>
                            In this work, we propose a new convolutional
                            operator that can adapt to object deformation.
                            And here we show conceptually how different 3-by-3
                            convolutions interact with deformations of two
                            images.
                            <b>(a, b)</b>
                            Conventional rigid kernels cannot adapt to object
                            deformation.
                            <b>(c)</b>
                            Previous work reconfigures data towards common
                            arrangement to counter the effects of geometric
                            deformation.
                            <b>(d)</b>
                            We propose to resample kernels and, in effect,
                            adapt kernel spaces while leaving the data
                            untouched.
                        </i>
                    </span>
                </center>
            </td>
        </tr>
    </table>

    <br>
    Convolutional networks are not aware of an object’s geometric variations,
    which leads to inefficient utilization of model and data capacity. To
    overcome this issue, recent works on deformation modeling seek to spatially
    reconfigure the data towards a common arrangement such that semantic
    recognition suffers less from deformation. This is typically done by
    augmenting static operators with learned free-form sampling grids in the
    image space, dynamically tuned to the data and task for adapting the
    receptive field. Yet adapting the receptive field does not quite reach the
    actual goal – what really matters to the network is the <i>effective</i>
    receptive field (ERF), which reflects how much each pixel contributes. It
    is thus natural to design other approaches to adapt the ERF directly during
    runtime.
    <br>
    In this work, we instantiate one possible solution as Deformable Kernels
    (DKs), a family of novel and generic convolutional operators for handling
    object deformations by directly adapting the ERF while leaving the
    receptive field untouched. At the heart of our method is the ability to
    resample the original kernel space towards recovering the deformation of
    objects. This approach is justified with theoretical insights that the ERF
    is strictly determined by data sampling locations and kernel values. We
    implement DKs as generic drop-in replacements of rigid kernels and conduct
    a series of empirical studies whose results conform with our theories.
    Over several tasks and standard base models, our approach compares
    favorably against prior works that adapt during runtime. In addition,
    further experiments suggest a working mechanism orthogonal and
    complementary to previous works.
    <br>
    <br>
    <hr>
    <!-- <table align=center width=550px> -->
    <center><h1>Results</h1></center>
    <table align=center width=900px>
        <tr>
            <td width=1200px>
                <center>
                    <img src = "qualitative.png" height="500px"></img><br>
                </center>
            </td>
        </tr>
        <tr>
            <td width=600px>
                <center>
                    <span style="font-size:14px">
                        <i>
                            Qualitative results of our method. From left to
                            right, reference image, depth, optical flow and
                            instance-level moving object mask.
                        </i>
                    </span>
                </center>
            </td>
        </tr>
    </table>
    <br>
    <hr>
    <table align=center width=800>
        <center><h1>Paper</h1></center>
        <tr>
            <td><a href="https://arxiv.org/pdf/1910.02940.pdf"><img style="width:400px" src="thumbnail.png"/></a></td>
            <td><span style="font-size:14pt">Cao, Kar, H&auml;ne, Malik.<br><br>
                    Learning Independent Object Motion from <br> Unlabelled Stereoscopic Videos<br><br>
                    In CVPR, 2019.<br><br>
                    <a href="https://arxiv.org/pdf/1901.01971.pdf">[pdf]</a> &nbsp; &nbsp;
                    <a href="bibtex.txt">[Bibtex]</a>
                    <!-- [hosted on <a href="#">arXiv</a>]</a> -->
            </td>
        </tr>
    </table>
    <br>
    <hr>

      <center><h1>Code</h1></center>
      <table align=center width=1000px>
        <tr>
          <center>
            <a href='#'><img class="round" style="height:400" src="architecture.png"/></a>
          </center>
        </tr>
      </table>

      <table align=center width=800px>
        <tr>
          <center> <br>
            <span style="font-size:28px">&nbsp;<a href='#'>[GitHub]</a>  (coming soon)
            <span style="font-size:28px"><a></a></span>
            <br>
          </center>
        </tr>
      </table>
      <br>
      <hr>


            <table align=center width=1100px>
                <tr>
                    <td>
                      <left>
                <center><h1>Acknowledgements</h1></center>
                We thank members of the BAIR community for helpful discussions and comments. This webpage template was borrowed from some <a href="https://richzhang.github.io/colorization/">colorful folks</a>.
            </left>
        </td>
        </tr>
        </table>

        <br><br>
</body>
</html>
